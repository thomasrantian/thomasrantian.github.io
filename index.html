
<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ran (Thomas) Tian</title>
  
  <meta name="author" content="Minae Kwon">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/favicon.ico">

</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- <hr> -->
          <tr style="padding:0px;text-align:left">
            <td style="padding-left:2.5%;padding-right:2.5%;padding-top:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:left">
                <name>Ran (Thomas) Tian - 田然</name>
                <br>
                rantian [at] berkeley [dot] edu 
              </p>

              <!-- <p style="display:inline;color:#ff0066;"> -->
              <!--<p style="display:inline;color:#f18800;">
                <b>News TBD</b>
              </p>-->
            
              <!--<p style="color:black;">
                <i class="fa fa-bullhorn" aria-hidden="true"></i><b> I am recruiting PhD students for Fall 2023! Check out more information on joining the lab <a href="join.html">here</a>.</b>
              </p>-->

              <p>
              I am a PhD student at <a href="https://bair.berkeley.edu//">UC Berkeley</a> 
              advised by <a href="https://msc.berkeley.edu/">Prof. Masayoshi Tomizuka</a> 
              and <a href="https://cmu-intentlab.github.io/">Prof. Andrea Bajcsy</a> at Carnegie Mellon University.
              I am currently a research scientist intern at the <a href="https://research.nvidia.com/labs/avg/">Autonomous Vehicle Research Group at NVIDIA Research </a>
              working on visual foundational models for autonomous driving.
              I spent Summer 2023 at <a href="https://waymo.com/research/">Waymo</a> 
              working on large autoregressive model for autonomous vehicle motion generation and efficient deployment.
              I also spent Summer 2022 at <a href="https://waymo.com/research/">Waymo</a> 
              working on learning autonomous vehicle behavior scoring function from human feedback.
              Previously, I was a research intern at <a href="https://www.weride.ai/WeRide">WeRide</a>,
              <a href="https://usa.honda-ri.com/">Honda Research Institute</a>, and <a href="https://www.qualcomm.com/research/artificial-intelligence/ai-research">Qualcomm AI Research</a>.
              </p>

              <p> 
                My research lies in the intersection of robotics and AI with a focus on 
                alignment between embodied agents and humans. <em>I am interested in enabling 
                embodied agents to act in accordance with human intentions and in close proximity
                to humans because they understand human preferences and the safety implications 
                that can arise from misaligned models.</em> 
                I ground my work through a variety of
                applications, from autonomous cars, to personalized robots, to generative AI and
                in experiments with real human participants.
              </p>

              <p> 
                I sincerely appreciate the fellowship support from <a href="https://www.weride.ai/WeRide">WeRide</a> (thank you! Dr. Yan Li and Dr. Tony Han)
                for funding my research in my first two years of study!
              </p>


              <p style="text-align:left">
                <!-- <a href="mailto:minae@cs.stanford.edu"><b>email</b></a> &nbsp&nbsp|&nbsp&nbsp -->
                <!--<a href="minae_cv.pdf"><b>cv</b></a> &nbsp&nbsp|&nbsp&nbsp-->
                <a href="https://scholar.google.com/citations?user=uY4D8-wAAAAJ&hl=en&authuser=1"><b>google scholar</b></a> &nbsp&nbsp|&nbsp&nbsp
                <!-- <a href="https://twitter.com/minaekwon"><b>twitter</b></a> &nbsp&nbsp -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/personal-image.jpg"><img style="width:100%;max-width:100%;border-radius:15%" alt="profile photo" src="images/personal-image.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody>
      </table>
      
      <p></p>

      <!-- news feed -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
            <td style="padding-left:2.5%;padding-bottom:20px;width:100%;vertical-align:middle">
              <heading><b>News</b></heading>
              <p>
                <ul class="fa-ul">
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[May 2024]</p> I was named a <a href=" https://sites.google.com/view/rsspioneers2024/"> Robotics: Science and Systems Pioneer</a> this year (top 30 early career researchers around the world in the robotics filed)!</li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Apr 2024]</p> I won the <a href=" https://www.qualcomm.com/research/university-relations/innovation-fellowship/2024-north-america"> 2024 Qualcomm Innovation Fellowship </a> (32 winners in north america)!</li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Mar 2024]</p> I won the finalist award in the <a href="http://scholarship.baidu.com/"> Baidu AI Fellowship </a> this year (top 20 Phd students in the AI filed around the world)!</li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Mar 2024]</p> Check out our new <a href="https://arxiv.org/abs/2403.04745 ">preprint</a> on a general calibrated regret metric for detecting and mitigating <b>system-level human-robot interaction failures</b> and how it can be used to identify informative deployment data for efficiently improving behavior prediction models.</li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Jan 2024]</p> Our work on visual representation alignment for robot learning was accepted to ICLR 2024! Check out the new results in the <a href="https://arxiv.org/pdf/2310.07932.pdf">arXiv version</a>.</li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Jan 2024]</p> I am starting my internship at NVIDIA Research! </li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Nov 2023]</p> Check out our new <a href="https://arxiv.org/pdf/2310.07932.pdf">preprint</a> in which we propose a tractable video-only method for solving the visual representation alignment problem and learning visual robot rewards! </li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Oct 2023]</p> Together with Google Brain, DeepMind, and 34 labs around the world, we released our dataset for large scale robot learning! </li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[May 2023]</p> I will be starting an internship at Waymo! </li>
                  <li><i class="fa fa-chevron-right"></i> <p style="display:inline;color:#f18800;">[Jan 2023]</p> Our paper on modeling & influencing the dynamics of human learning was accepted to HRI 2023! </li>
                </ul>
              </p>
            </td>
          </tr>
          </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
            <td style="padding-left:20px;padding-bottom:0px;width:100%;vertical-align:middle">
              <heading><b>Publications</b></heading>

              <p>For the most up-to-date list of publications, please see <a href="https://scholar.google.com/citations?user=uY4D8-wAAAAJ&hl=en&authuser=1">google scholar</a>. 
                <br>
                <p><i>* indicates equal contribution and co-authorship.</i></p>
            </td>
          </tr>
          </tbody>
        </table>



        <!---------------------------- Publications 2023 -------------------------->

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/tian_rapl_23.png" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/abs/2310.07932">
                <papertitle>What Matters to You? Towards Visual Representation Alignment for Robot Learning</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Chenfeng Xu, Masayoshi Tomizuka, Jitendra Malik, Andrea Bajcsy 
              <br>
              <em>Preprint, 2023</em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/abs/2310.07932"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <p></p>
            </td>
            </tr> 

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/RT-X-vis.gif" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://robotics-transformer-x.github.io/paper.pdf">
                <papertitle>Open X-Embodiment: Robotic Learning Datasets and RT-X Models</papertitle>
              </a>
              <br>
              Google, <b>Ran Tian</b>, et al.
              <br>
              <em>Preprint, 2023</em>
              <br>
              <br>
              <a class="button-paper" href="https://robotics-transformer-x.github.io/paper.pdf"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <a class="button-website" href="https://robotics-transformer-x.github.io/"><i class="fa fa-rss" aria-hidden="true"></i> website</a>
              <p></p>
            </td>
            </tr>

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/huo_human_2023.gif" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://sites.google.com/view/human-oriented-robot-learning">
                <papertitle>Human-oriented Representation Learning for Robotic Manipulation</papertitle>
              </a>
              <br>
              Mingxiao Huo, Mingyu Ding, Chenfeng Xu, <b>Ran Tian</b>, Xinghao Zhu, Yao Mu Lingfeng Sun, Masayoshi Tomizuka, Wei Zhan
              <br>
              <em>Preprint, 2023</em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/pdf/2310.03023.pdf"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <a class="button-website" href="https://sites.google.com/view/human-oriented-robot-learning"><i class="fa fa-rss" aria-hidden="true"></i> website</a>
              <p></p>
            </td>
            </tr> 

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/HRI_23.png" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/pdf/2301.00901.pdf">
                <papertitle>Towards Modeling and Influencing the Dynamics of Human Learning</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Masayoshi Tomizuka, Anca Dragan, Andrea Bajcsy
              <br>
              <em>International Conference on Human-Robot Interaction (HRI), 2023
              </em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/pdf/2301.00901.pdf"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <a class="button-talk" href="https://www.youtube.com/watch?v=KGsVm0qXDAc&t=3s"><i class="fa fa-volume-up" aria-hidden="true"></i> talk</a>
              <p></p>
            </td>
            </tr> 

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/tian_2022.gif" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/abs/2109.14700">
                <papertitle>Safety Assurances for Human-Robot Interaction via Confidence-aware Game-theoretic Human Models</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Liting Sun, Andrea Bajcsy, Masayoshi Tomizuka, Anca Dragan
              <br>
              <em>International Conference on Robotics and Automation (ICRA), 2022</em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/abs/2109.14700"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <a class="button-talk" href="https://www.youtube.com/watch?v=YZlwMxepGtc&list=PLjbUVJgrbvfnyEXcYwEsTTLnsHu9_cuJa&index=6"><i class="fa fa-volume-up" aria-hidden="true"></i> talk</a>
              <p></p>
            </td>
          </tr> 

        </tbody>
      </table>
        <!---------------------------- Publications 2022 -------------------------->

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/icra_22_goal_inference.png" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="pdfs/ICRA_22_Tian_Cost_Effective_Goal_Inference.pdf">
                <papertitle>Cost-Effective Sensing for Goal Inference: A Model Predictive Approach</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Nan Li, Anouck Girard, Ilya Kolmanovsky, Masayoshi Tomizuka
              <br>
              <em>International Conference on Robotics and Automation (ICRA), 2022</em>
              <br>
              <br>
              <a class="button-paper" href="pdfs/ICRA_22_Tian_Cost_Effective_Goal_Inference.pdf"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              <p></p>
            </td>
          </tr> 

          <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/IROS_intro.png" style="border-radius:5%/10%;width:200px"></td>
          <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/abs/2103.04289">
                <papertitle>Learning Human Rewards by Inferring Their Latent Intelligence Levels in Multi-Agent Games: A Theory-of-Mind Approach with Application to Driving Data</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Masayoshi Tomizuka, Liting Sun
              <br>
              <em>International Conference on Intelligent Robots and Systems (IROS), 2021</em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/abs/2103.04289"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
            </td>
          </tr> 
        </tbody>
      </table>
        <!---------------------------- Publications 2021 -------------------------->

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/AAAI_21_tian.png" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="pdfs/AAAI2021_BRSMG_full.pdf">
                <papertitle>Bounded Risk-sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Liting Sun, Masayoshi Tomizuka
              <br>
              <em>AAAI Conference on Artificial Intelligence, 2021</em>
              <br>
              <br>
              <a class="button-paper" href="pdfs/AAAI2021_BRSMG_full.pdf"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <p></p>
            </td>
          </tr> 

          <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/icra_21_tian.gif" style="border-radius:5%/10%;width:200px"></td>
          <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/abs/2109.12490">
                <papertitle>Anytime Game-theoretic Planning with Active Reasoning about Humans’ Latent States for Human-centered Robots</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Liting Sun, Masayoshi Tomizuka, David Isele
              <br>
              <em>International Conference on Robotics and Automation (ICRA), 2021</em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/abs/2109.12490"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <p></p>
            </td>
          </tr> 
        </tbody>
      </table>

        <!---------------------------- Publications 2020 -------------------------->

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/ccta_20_tian.png" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="pdfs/Tian_CCTA_20.pdf">
                <papertitle>Controller Mode and Reference Governor for Constraint and Failure Management in Autonomous Vehicle Platooning</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Nan Li, Anouck Girard, Ilya Kolmanovsky
              <br>
              <em>Conference on Control Technology and Applications, 2020</em>
              <br>
              <p style="display:inline;color:#f18800;">(Honorable Mention for Best Paper)</p>
              <br>
              <br>
              <a class="button-paper" href="pdfs/Tian_CCTA_20.pdf"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <a class="button-talk" href="https://www.youtube.com/watch?v=zw_WWu7-g0k"><i class="fa fa-volume-up" aria-hidden="true"></i> talk</a>
              &nbsp
              <p></p>
            </td>
          </tr> 
          
            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/tian_acc_20.png" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/abs/1909.12701">
                <papertitle>Beating Humans in a Penny-matching Game by Leveraging Cognitive Hierarchy Theory and Bayesian Learning</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Nan Li, Anouck Girard, Ilya Kolmanovsky
              <br>
              <em>American Control Conference(ACC), 2021</em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/abs/1909.12701"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <a class="button-talk" href="https://www.youtube.com/watch?v=SZz-__7Af7Y"><i class="fa fa-volume-up" aria-hidden="true"></i> talk</a>
              <p></p>
            </td>
          </tr> 

        </tbody>
      </table>

        <!---------------------------- Publications 2019 -------------------------->

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/tian_tits_20.gif" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/abs/1910.07141">
                <papertitle>Game-Theoretic Modeling of Driver Social Interactions</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Nan Li, Ilya Kolmanovsky, Yildiray Yildiz, Anouck Girard
              <br>
              <em>IEEE Transactions on Intelligent Transportation Systems, 2020</em>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/abs/1910.07141"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <p></p>
            </td>
          </tr> 
        </tbody>
      </table>

        <!---------------------------- Publications 2018 -------------------------->

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/tian_cdc_2018.gif" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://arxiv.org/abs/1810.00829">
                <papertitle>Adaptive Game-Theoretic Decision-Making for Autonomous Vehicle Control at Roundabouts</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Sisi Li, Nan Li,  Ilya Kolmanovsky, Anouck Girard
              <br>
              <em>Human Robot Interaction (HRI)</em>, 2018
              <br>
              <p style="display:inline;color:#f18800;">(Best Paper Nomination)</p>
              <br>
              <br>
              <a class="button-paper" href="https://arxiv.org/abs/1810.00829"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <p></p>
            </td>
          </tr> 
            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/rollover.gif" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://ieeexplore.ieee.org/document/8063352">
                <papertitle>Reference Governor Strategies for Vehicle Rollover Avoidance</papertitle>
              </a>
              <br>
              Ricardo Bencatel, <b>Ran Tian</b>, Anouck Girard, Ilya Kolmanovsky
              <br>
              <em>IEEE Transactions on Control Systems Technology, 2017</em>
              <br>
              <br>
              <a class="button-paper" href="https://ieeexplore.ieee.org/document/8063352"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <p></p>
            </td>
          </tr> 
        </tbody>
      </table>

        <!---------------------------- Publications 2016 -------------------------->

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding-left:20px;padding-bottom:20px;width:15%;vertical-align:middle"><img src="paper_imgs/icuas_17.PNG" style="border-radius:5%/10%;width:200px"></td>
            <td style="padding-left:35px;padding-bottom:20px;width:100%;vertical-align:left">
              <a href="https://ieeexplore.ieee.org/document/7991386">
                <papertitle>Path Planning for Information Collection in Contested Environments using Marsupial Systems</papertitle>
              </a>
              <br>
              <b>Ran Tian</b>, Hao Chen, Gregory Frey, Bingqing Zu, Anouck Girard, Ilya Kolmanovsky.
              <br>
              <em>IEEE International Conference on Unmanned Aircraft Systems, 2017</em>
              <br>
              <br>
              <a class="button-paper" href="https://ieeexplore.ieee.org/document/7991386"><i class="fa fa-file-text" aria-hidden="true"></i> paper</a>
              &nbsp
              <p></p>
            </td>
          </tr> 
        </tbody>
      </table>

    <hr>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0" style="padding-top:0px;">
      <tbody>
        <tr>
        <td>
        <br>
        <p align="center" style="font-size:small;color:grey;">
          website adapted from <a href="https://people.eecs.berkeley.edu/~abajcsy/" style="font-size:small;">here</a>
          </font>
        </p>
        </td>
        </tr>
      </tbody>
    </table>

</body>

</html>

